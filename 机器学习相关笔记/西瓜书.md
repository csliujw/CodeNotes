# SVM

Support vector machine

对于样本量小的，用SVM往往可以得到很好的效果。但处理大数据集，SVM不是很合适。【问题：什么规模的算小，什么规模的算大】

## 线性模型

线性可分，可通过一条直线进行划分。

将直线两端平移，直到插到了要划分的那些向量，那些被插入的向量叫支持向量。被平移的线到原线的距离叫间隔，svm要找的是那个最小间隔。

问题逐渐变为 求最小间隔（线与线的平行距离）

在求解的时候对方程进行了放缩，以简化求解。

<span style="color:red">笔记阅读流程：P121-P123顺序观看</span>

## 非线性模型

非线性模型，不可以通过一条直线进行划分。

为此，我们把当前的低维空间上升为高维空间，在高维空间中用直线进行划分。

一个说法：维度越高，被线性分开的概率越大。如果是无限维度，那么他线性可分的概论将会是1，西瓜书P126笔记（非线性映射）

我们不知道怎么把低维映射到高维【无限维映射的显示表达式】，我们需要只要知道一个核函数（Kernal Function），用核函数替代显示表达式（这个表达式维数可能很高，故采用核函数）。

- 核函数：替代了低维映射到高维的那个函数fai。
- 用核函数替代fai，简化优化问题

之后补充了下最优化论的知识。

为什么要引入原问题 ， 对偶问题， 强对偶定理？

目的是为了只用K不用fai解决那个问题。

用原问题解决对偶问题。用原问题的方式解决对偶问题。

视频：胡浩基，机器学习11

----

**思路整理：**

非线性如何划分？

将低维-----映射----->高维

通过核函数将低维映射到高维（维度越高，线性可分的概率越大）

如何用核函数取代fai。

- 核函数取代fai的充要条件（A4纸笔记）
  - K( X1 , X2 ) = K( X2 , X1 )
  - 半正定
- 途中引入了优化理论的内容
  - 在特定条件，可以用 通过原问题的方式解决对偶问题（证明见A4纸笔记）
  - 引出了原问题和对偶问题，在特定条件下，原问题和对偶问题的解是一致的。我们把对原问题的求解化为了对偶问题的求解。这样我们只要求对偶问题的解就可以了。<span style="color:red">统计学习方法中有详细推导说明</span>

<span style='color:red'>笔记阅读流程：130->126->127->123对偶问题</span>

但是有个核函数可以完成这个工作。

我们可以不知道 

后向传播算法。

从后向前算偏导。先计算连接最为丰富的那些参数的偏导（如b和w1，w2，b1有关，我们先计算偏E/偏b  【E是损失函数（预测值和真实值之间的差距）】）这样做的好处好像是减少了直接一个一个求偏导的计算量。

一键安装依赖
sudo apt-get -f install

## 参数设置
- 随机梯度下降
	不用每输入一个样本就去变换参数，而是输入一批样本（叫做一个BATCH或MINI-BATCH），求出这些样本的梯度平均值后，根据这个平均值改变参数
	在NN训练中，BATCH的样本数大致设置为50-200不等
	
- 激活函数（非线性函数）
	sigmoid （0~-1） 求导简单 
	tanh（-1~1）
	ReLU
	Leaky ReLU
	Maxout
	ELU
	
- 训练数据初始化
	建议做归一化：如均值和方差归一化
	为了输入的特征，每一个维度对后面的影响差不多
	
- 梯度消失现象（sigmoid 函数 和 tanh函数）
	如果(W^T) * X + b 一开始很大或很小，那么梯度将趋近于0，反向传播后前面与之相关的梯度也趋近于0，导致训练缓慢。（后面的偏导趋近于0，那么后向传播的时候，那些值也会趋近于0，导致计算缓慢）
	因此，我们要使(W^T) * X + b一开始在零附近。
	简单有效的方法：（W，b）初始化从区间 （负的根号d 分之一，根号d 分之一）
	
- Batch Normalization
	基本思想：我们希望每一层获得的值都在0附近，从而避免梯度消失现象，那么我们为什么不直接把每一层的值做基于均值和方差的归一化呢？
	每一层FC（Fully Connected Layer）
	接一个BN（Batch Normalization）层
	
- 目标函数的选择
	- 可加正则项
	- 如果是分类问题，F（W）可采用SOFTMAX函数和交叉熵的组合
		- softmax 强行把分类转换成概率
		- cross entropy  
		
## 参数更新策略

深度学习优化算法经历了 SGD -> SGDM -> NAG ->AdaGrad -> AdaDelta -> Adam -> Nadam 这样的发展历程

- W_{k} = W_{k} - lr * W_grad(k)
- SGD的问题
	- （W，b）的每一个分量获得的梯度绝对值有大有小，一些情况下，将会迫使路径变成Z字形状。
	- SGD求梯度的策略过于随机，由于上一次和下一次用的是完全不同的BATCH数据，将会出现优化的方向随机的情况。
	- 解决各个方向梯度不一致的方法
		- AdaGrad 
		- RMSProp 
	- 解决梯度随机性问题
		- momentum （角动量）
		每一次更新一个v（速度），第一次算出的方向让他第二次还有一点点影响（让上一次的方向对这次有影响）
	- Adam（把所有方法都综合在一起）
		- 规整梯度分量让它们差不多，让梯度的方向相对平缓。
	- 参考<a href="https://zhuanlan.zhihu.com/p/32230623">网站</a>
		
## 总结
> **老师的经验之谈**
- Batch Normalization 比较好用，用了这个后，对学习率，参数更新策略等不敏感。建议用BN。更新策略用最简单的SGD即可，加上其他反而不好
- 如果不用BN，合理变换其他参数组合，也可达到目的
- 由于梯度累积效应，AdaGrad、RMSProp、Adam三种更新策略到了训练的后期会很慢，可以采用提高学习效率的策略来补偿这一效应。

问下为什么。

# 人工神经网络的历史 - 多层网络

## 多层网络
优势和劣势是对比SVM
### 优势
- 基本单元简单，多个基本单元可扩展为非常复杂的非线性函数。因此易于构建，同时模型有很强的表达能力
- 训练和测试的计算并行性非常好，有利于在分布式系统上应用
- 模型构建来源于对人脑的仿生，话题丰富，各种领域的研究人员都有兴趣，都能做贡献。


### 劣势
- 数学不漂亮，优化算法只能获得局部极值，算法性能与初始值有关。
- 不可解释。训练神经网络获得的参数与实际任务的关联性非常模糊
- 模型可调整的参数很多（网络层数、每层神经元个数、非线性函数、学习率、优化方法、终止条件等），使得训练神经网络变得很玄学。
- 若要训练相对复杂的网络，需要大量的训练样本。

## 深度学习工具

- 数据库介绍
	- ImageNet
		- 1000类 100多万张（09年）
		- 图片大小：正常图片大小，像素 几百*几百
		- WORDNET结构，拥有多个Node。一个node至少500个对应物体的可供训练的图片/图像
		- 算法都差不多，重点在数据的比拼？（算法不够准？加几个数量级试试？）
- 自编码器（Auto encoder）  部分解决了神经网络参数初始化的问题
	- 是一种利用反向传播算法使得输出值等于输入值的神经网络，它先将输入压缩成潜在空间表征，然后通过这种表征来重构输出。
- 卷积神经网络（Convolutional Neural Networks）
- 深度学习框架 TensorFlow PyTorch
- 流行的CNN网络结构 LeNet AlexNet VGGNet GoogLeNet(2014) ResNet






















































​		
​		
​		
​		
​		



