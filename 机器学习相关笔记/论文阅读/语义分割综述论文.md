#  论文名称

深度卷积神经网络图像语义分割研究进展_青晨

#  摘要

论文摘要：扼要说明研究工作的目的、研究方法和最终结论。

本文首先分析和描述了语义分割 领域存在的困难和挑战，介绍了语义分割算法性能评价的常用数据集和客观评测指标。然后，归纳和总结了现阶 段主流的基于深度卷积神经网络的图像语义分割方法的国内外研究现状。

# 引言

语义分割是像素级的图像理解，对图像中的每一个像素标注所属类别。

传统图像分割算法的分割策略。

- 通过图像的颜色、纹理信息、空间结构等特征，将其分割为不同的区域。同一区域内具有一致的语义信息。

传统图像的分割方法

-  阈值分割
- 区域生长
- 边缘检测
- 图划分
- 归一化分割（经典分割方法）
- `GrabCut`（经典分割方法）

提出深度学习概念后，利用多层神经网络从大量训练数据中自动学习高层特征。对比传统手工设计的特征，`DCNN`学习的特征更加丰富、表达能力更强。利用`DCNN`可以实现端到端的语义分割预测。

语义分割难点

- 目标：不同光照、角度、距离等条件下，拍摄的图像会明显不同。
- 类别：同类目标之间存在相异性，而不同类目标之间存在相似性的问题。
- 背景：实例场景中的背景是复杂的，不利于实现语义分割。

该综述将

- 详细描述了每种方法的创新工作并分析了**存在的问题**。
- 介绍语义分割存在的**问题与挑战**。
- 语义分割算法性能评价的常用数据集和客观评测指标。
- 指出了语义分割领域**未来的研究方向**。

#   常用数据集与评测指标

## 常用数据集

- PASCAL VOC 
- MS COCO( microsoft common objects in context)
- KITTI ( Karlsruhe Institute of Technology and Toyota Technological Institute)
- PASCAL-Part
- Cityscapes
- CamVid( Cambridge-driving labeled video database) 
- etc....

## 客观评测指标

- 运行时间

- 显存占用

- 准确率

  - 像素准确率 pixel accuracy，PA 分类正确的像素占总像素的比例。但是，不同类别的样本数量差别很大的情况时，像素准确率并不能客观反映模型性能。
  - 平均像素准确率( mean pixel accuracy，`MPA`)
  - 平均交并比( mean intersection-over-union，`MIoU`) ==最重要！，更能反映模型的准确程度==

  假设一共有 c + 1 个类别( 包括一个背景类) ，记 `pij` 是将 i 类预测为 j 类的像素数，换句话说，`pii` 表示 正确预测的正样本的像素数( true positives) ; `pij` 和 `pji` 分别表示错误预测的正样本的像素数( false positives) 和错误预测的负样本的像素数( false negatives) 。**像素准确率是分类正确的像素占总像素的比例**（如果每个类别之间的数量差距大，但是数量多的类别识别率高，数量上的类别识别率低，这种判断方式是不合理的！），可表示为：

  $P = \frac{\sum_{i=0}^{c} P_{ii}}{\sum_{i=0}^{c}\sum_{j=0}^c P_{ij} }$

  平均像素准确率计算**每个类内准确分类像素数的比例**，**再求所有类的平均**，可表示为：

  $P = \frac{1}{c+1} \sum_{i=0}^c \frac{P_{ii}}{\sum_{j=0}^c P_{ij}}$

  **==平均交并比是语义分割性能的标准度量值==**，计算正确预测的正样本( 真实值与预测值这两个集合的交集) 与正确预测的正样本、错误预测的正样本 和错误预测的负样本之和( 并集) 的比值，可表示为：

  $R_{MIou} = \frac{1}{c+1} \sum_{i=0}^c \frac{P_{ii}}{\sum_{j=0,j \neq i} (P_{ij}+P_{ji})+P_{ii}}$

#  基于监督学习的语义分割模型

需要预先标注训 练图像的每一个像素，再利用标注好的数据集训练 语义分割网络。[ 这工作量很大啊。。。 ]

## 大致分类

- 基于解码器的方法  [ `FCN` `U-Net` ]
- 基于特征图的方法 [ `DeepLab v3`,改进了空洞空间金字塔池化,用不同扩展率的多个并行的空洞卷积层实现多尺度处理 ]
- 基于概率图的方法 [  ]
- 多种策略结合的方法

## 基于解码器的方法

**编码**：为图像生成低分辨率的特征图

**解码**：通过上采样将低分辨率的特征图映射到原图像尺寸，产生像素级的语义标签。[ 这样上采用得到的图像还是存在相对严重的问题 ]

解码器的输出是一个表示 图像类别标签( class label) 的矩阵，矩阵中每一个元 素的值与像素所属的类别相对应。

2015年提出的`FCN`，将传统的CNN最后的3个连接层替换为卷积层，输出一个类别标记矩阵，实现像素到像素的映射。

### **`FCN`**

由于全卷积网络不使用全连接层，因此不受全连接层参数的限制（不是很理解？是计算速度不手全连接参数的影响吗？可以不太考虑图片尺寸带来的无法收敛的问题？绝大多数的参数好像都是在全连接层！==讨论==），可以输入任意尺寸的图像。

**`FCN`的做法**

为了恢复特征图的空间维度，全卷积网络对每层的特征图利用==双线性插值进行上采样==，然后逐像素分类，生成与输入图像尺寸相 同的分割结果。由于池化操作造成的信息损失，通 过简单的上采样只能获得粗略的分割结果，因此该 方法融合了多分辨率的信息，即对不同尺寸的特征 图分别上采样后进行特征融合，从而获得更准确的 分割结果。

`FCN`的具体做法是 全连接变为了卷积，在这3个卷积层，保留了每层的特征。同时作者还尝试了把最前面几层的特征图保留融合，但是效果并不理想。

**`FCN`的不足**

虽然全卷积网络融合了多分辨率信息， 但是通过简单的双线性插值得到的分割结果仍较为模糊和粗糙，无法完整地还原图像中的细节信息。

### U-Net

具有对称编码器-解码器结构的U-Net

对`FCN`结构进行改进。编码器部分与`FCN`相似，通过卷积与池化操作提取特征，而在解码器部分中，U-Net 将编码器每一层输出的特征图与对应的解码器生成的特征图相融合，即将深层语义特征与细粒度的浅层细节特征 相结合，从而生成更准确的分割图像。

这样看`FCN`和`UNet`的区别似乎没那么明显！

- U-net与其他常见的分割网络有一点非常不同的地方：U-net采用了完全不同的特征融合方式：拼接，U-net采用将特征在channel维度拼接在一起，形成更厚的特征。而`FCN`融合时使用的对应点相加，并不形成更厚的特征。
- `FCN`式的对应点相加，对应于`TensorFlow`中的`tf.add()`函数；
  U-net式的channel维度拼接融合，对应于`TensorFlow`的`tf.concat()`函数，比较占显存。

<a href="https://blog.csdn.net/weixin_41108334/article/details/87917748">对应博客</a>

### 全卷积网络的问题

- 网络预定义了感受域( receptive field) 的大小，所以*大于或者小于感受域的目标，可能被分裂或者错误标记*; 
- 二是由于上采样操作( 双 线性插值) 过于简单，使得目标的细节信息丢失或者被平滑处理。

### 解决

提出了一种对称的语义分割网络模型`DeconvNet`。

编码器部分：采用`VGG16`

解码器部分：由多层转置卷积网络代替简单的上采样操 作，生成比全卷积网络更准确的分割图。

多层转置 卷积网络包括上池化层( `unpooling layers`) 和转置卷 积层( deconvolution layers) 。在池化过程中利用切 换变量( `switch variables`) 记录最大池化操作确定的最大激活值的位置，然后上池化层利用转换变量将 最大激活值映射回原来的位置，从而恢复图像的空 间分辨率，其他像素值用 0 填充，生成稀疏的特征图。（<u>记录最大池化的位置，再还原回原来的位置，其他地方填充为0</u>）。再用转置卷积转换为稠密图。

### `SegNet`

好像被`Resnet`碾压了。。

种旨在应用于智能驾驶和机器人领域的语义分割模型，主要以道路场景理解为动机，具有对外观(道路、建筑物) 和形状( 汽车、行人) 建模的能力，能够学习不同类别(如道路和人行道)之间的上下文关系。

`SegNet`去掉了全连接层，减少了参与训练的参数数量，从而提高了预测结果的效率。`SegNet` 增加了批归一化操作，加快了网络的收敛速 度并抑制了过拟合现象。

目标边界的分割 精度仍然有待提高。

## 基于特征图的方法

### 膨胀卷积

结合特征图的上下文信息：

- 空间上下文（位置）不理解 [ 空间上下文，增大感受域？] 
- 尺度上下文（尺寸）

这类方法通过增大感受域和融合多尺度可以获得空间上下文和尺度上下文，可有效提升网络的分割性能。

以 FCN 和 SegNet 为代表的语义分割模型都利用卷积结合池化操作提取特征。池化的目的是缩小 图像尺寸、降低计算量和避免过拟合。由于语义分 割需要得到像素级的预测，所以需要进行上采样操 作，使输出图像的尺寸与输入图像的尺寸保持一致。 经过了下采样和上采样操作，图像丢失了大部分信 息，使得语义分割的精度下降。

用膨胀卷积来代替池化层和上采样层。

dilated convolution（膨胀卷积、空洞卷积）：通过再卷积核之间填充固定数量的0元素，达到在不增加卷积核参数数量的情况下使用卷积核的感受域增大。

<img src="..\..\pics\pytorch\dilated_convolution.gif" style="float:left">

膨胀卷积，卷积核不连续，损失了图像连续性信息，不利于小目标的分割。

<a href="https://blog.csdn.net/qq_30241709/article/details/88080367">知识有限，暂时靠博客续命</a>

### DeepLab v3

改进了空洞空间金字塔池化（atrous spatial pyramid pooling，ASPP）模型。，使用不同扩张率的多个并行的空洞卷积层实现多尺度处理。

空洞卷积的计算方式

<img src="..\..\pics\pytorch\dilation_rate.jpg">

`DeepLab v3`采用 不同的扩张率，用多个并行的空洞卷积层实现多尺度处理，并添加了全局平均池化。

==DeepLab v3示意图==

<img src="..\..\pics\pytorch\DeepLab_v3.png">

`DeepLab v1 v2`加入了v一个条件随机场，那个好像优化起来很麻烦，效果也不好，略过？？











































