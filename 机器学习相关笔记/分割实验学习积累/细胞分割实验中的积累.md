# 基础知识的补充

## batch size

batch size 是把好几个数据，用同样的网络参数同时训练~

比如：一张28*28的图片，展平后变成784个元素。我们一次性打包处理100张图像。可以把x的形状改为$100 * 784$，然后训练数据~

其他的关于batch size 对结果的影响，之前看了几篇博客，但是记得不是很清楚了，后面再补充

# 理论和方法层面

- U-Net 为了分割细胞的边界，引入了权重
- 结合了局部信息和全局信息，U型结构
- 无法还原图片大小,我们采用了padding填充，图片可以还原成原来的大小

## 模型的修改

### `UNet`

个别图片效果很好，个别图片效果很差。

### `UNet++`

效果不咋地。基本很难看到完整的细胞。（这也很我保存模型参数的不合理有关）

### `nnUNet`

`UNet to UNet++`效果并不好，又换回了`UNet`之后老师说用`nnUNet`，于是我把`UNet`的模型按`nnUNet`进行了部分调整，但是并未完全按照`nnUNet`进行修改，调整策略如下：

```shell
relu --> LeakyRelu
BatchNorm2d --> InstanceNorm2d
```

看了下控制台跑的效果，似乎是好了很多~~

## 调参

### 实践过的

根据训练效果进行调整

> **学习率的调整，用的是`PyTorch`的一个`function`**

```python
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)
```

意思是每20次调整一次学习率，调整为原来的0.7，自动调参~~

> **步长**

> **网络层数**

- 还未真正尝试过加网络层数
- 尝试过`UNet++`，加了网络层数（不只是修改了网络层数），局部信息，但是效果不佳~

> **批训练数据，取均值**

这个过程是逐步调整的。

- 最开始，我们用的是每跑一小块图片，然后看这小块图片上的`miou`，根据`miou`的值保存模型，但是这样会出现只是个别图片效果特别好的情况，效果不好，要换策略了~
- 然后，我把图片分割成了4份，跑完这四份后取了倒数第二的`miou`对应的参数进行保存，但是效果也不好，`miou`没多久就到0.99了，情况很极端。
- 然后，问了下师姐，她随口说了一句给了很多提示。就按她说的来试了下，目前效果还行，暂时没出现极端情况~
  - 具体措施：因为害怕个别图片的极端情况，于是，我用同样的网络参数训练20张图片，算出他们的平均`miou`，以这个指标进行判断，是否保存当前的模型。多取了一些图片，可以避免随机性。后面看了下输出的`miou`，是在逐步提高，没出现啥极端情况，但是训练多少张图片取均值，还是要再测一测~（当时想试怎么就没试呢..）

### 未实践的想法

- 我们未还原`UNet`的镜像填充。我想试试~
- 我想按真实类别的比例，给各种类别加上合适的权重，以达到平衡的目的~

## 常用损失函数

预期损失有多大？

损失函数用平方还是非平方。

用损失函数计算损失的时候，要注意输入参数的形状。

```python
loss = criterion(masks_pred, mask.squeeze(0))
```

## 常用优化器



#  数据的一些基本处理

## 文件重命名

细胞的数据集中，一个图片中有多个符合要求的细胞，label是把符合要求的细胞是一个一个保存的。现在我想用一个图片其中的一个label图片进行训练，需要对文件进行重命名操作。

> <span style="color:green">**注意：**a.txt ; a.jpg这些是文件，目录他也是文件！</span>

**这只是提供一个最基础的模板，供未来2021年入学的编程和我一样菜的学弟学妹们参考**

```python
import os

# 基础目录
BASE_DIR = '/home/kkx/train/y/'

def func(path):
    # 遍历改目录中的所有文件（目录也是文件！）
    for i in os.listdir(path):
        # 拼接绝对路径
        path2 = os.path.join(path, i)  
         # 判断如果是文件夹,递归遍历  改文件夹
        if os.path.isdir(path2): 
            func(path2)
        # 是文件的话就重命名
        else:
            # 我的重命名是把后缀改了，这种写法不严谨，请勿模仿
            new_name = i.replace("gif", "jpg")
            # 文件重命名操作
            os.rename(BASE_DIR+i, BASE_DIR+new_name)

def func2(path):
    for i in os.listdir(path):
        path2 = os.path.join(path, i) # 拼接绝对路径
        if os.path.isdir(path2): # 判断如果是文件夹,调用本身
            func2(path2)
        else:
            # 获得后缀【我的文件名是123_23.bmp 我想把下划线后面的删除了，如123_23.bmp变成 123.bmp】
            end = i[-3:] # 取到后缀
            name = i.split('_')[0] # 获得文件名称
            new_name = name+'.'+end # 拼接新的name
            # 重命名
            os.rename(BASE_DIR+i,BASE_DIR+new_name)

if __name__ == "__main__":
    func2(BASE_DIR)

```

## OpenCV访问图片

```python
"""
找到文件，前缀相同的放在一个list里。
"""
import os
import numpy as np
import cv2 as cv
import logging

# 细胞壁
CELL_WALL = [20, 20, 20]
# 细胞核
CELL_KERNEL = [40, 40, 40]
# 背景色
CELL_BACKWORD = [0, 0, 0]
# 图片后缀名
IMAGE_SUFFIX = '.bmp'

logging.basicConfig(level=logging.DEBUG)

"""
修改下颜色复制的数值试一下，看看最后是不是单通道的元素。
"""
class process():

    def __init__(self, source_dir, target_dir):
        self.source_dir = source_dir
        self.target_dir = target_dir

    """获得文件的原始名,返回的数据格式为字典类型 {"file_name":[]}"""

    def get_primeval_name(self):
        file_name = os.listdir(self.source_dir)
        all_name = []
        for tmp in file_name:
            all_name.append(tmp.split("_")[0])
        # set去重
        singal_name = list(set(all_name))
        name_dict = {}
        for i in singal_name:
            name_dict[i] = []
        return name_dict

    """
    找到原始图片和名称一一对应的那些图
    return {  '1231':['123_1.jpg' , '123_2.jpg']  }
    """

    def find_suite_img(self):
        file_name = os.listdir(self.source_dir)
        name_dict = self.get_primeval_name()
        for i in file_name:
            primeval_name = i.split("_")[0]
            if primeval_name in name_dict.keys():
                name_dict[primeval_name].append(i)
        return name_dict

    """合并图片"""

    def merge_image(self):
        name_dict = self.find_suite_img()
        logging.info("total image count is {}".format(len(name_dict)))
        for key in name_dict.keys():
            logging.info("current key is {}".format(key))
            item_list = name_dict[key]
            """合并同一系列的图片 如 101_1.bmp 101_2.bmp"""
            self._merge_image(key, item_list)

    """合并同一原图的 label"""

    def _merge_image(self, key, item_list):
        image_obj = []
        for name in item_list:
            image_obj.append(cv.imread(self.source_dir + name))
        save_image = self.generate(image_obj[0])
        H, W = image_obj[0].shape[:2]
        # 能不能改成列表推导式
        logging.info("the key is {}".format(key))
        for h in range(H):
            for w in range(W):
                # 从所有的label的h w位置中选出最合适的像素点
                bgr = self.choose_best_pixel(h, w, image_obj)
                if bgr != [0, 0, 0]:
                    save_image[h, w] = bgr
        cv.imwrite(self.target_dir + key + IMAGE_SUFFIX, save_image)
        logging.info("save image {}".format(self.target_dir + key + IMAGE_SUFFIX))

    """
    *args : 像素值的元组，选择一个最好的 默认20 20 20最好
    暂时这样计算  20 20 20 是给了三通道吗？ 给20就好了
    """

    def choose_best_pixel(self, h, w, image_obj):
        cell_kernel = False
        cell_wall = False
        for tmp in image_obj:
            if (tmp[h, w] == CELL_WALL).all():
                cell_wall = True
            elif (tmp[h, w] == CELL_KERNEL).all():
                cell_kernel = True
        if cell_kernel:
            return CELL_KERNEL
        if cell_wall:
            return CELL_WALL
        return CELL_BACKWORD

    """
    生成一张空白图
    image_obj 
    """

    def generate(self, image_obj):
        obj = np.zeros(image_obj.shape, dtype=np.int8)
        H, W = image_obj.shape[:2]
        obj[:, :] = (0, 0, 0)
        return obj

if __name__ == "__main__":
    source_dir = '/home/qq/code/Pytorch-UNet/cell_data/patch_data/train/mask/'
    target_dit = '/home/qq/code/Pytorch-UNet/cell_data/patch_data/train/mask_copy/'
    p = process(source_dir=source_dir, target_dir=target_dit)
    p.merge_image()
```

## 图片合并

阿斯弗

## 图片上色

asf

## 训练过程中出现错误

原始的label是单通道 `8bit`的，我合成处理后的是24通道的图，所以`unet`训练报错了。

解决办法：

- `cv`分割出三个通道，然后将其中的一个通道保存为图片

  ```python
  """大致就这意思"""
  import cv2 as cv
  if __name__ == "__main__":
      obj = cv.imread("image_path")
      b,g,r = cv.split(obj)
      cv.write("image_path",b)
  ```

- <span  style="color:green">**PS：以后处理完数据后，要看下处理后的数据与原来的label在重要参数方面是否保持一致**</span>

# 语法和`API`层面的

## assert

```python
assert listA == listB, 'if A not equals B, string will print'
```

## logging

```python
import logging

logging.basicConfig(level=logging.DEBUG)
logging.info("safd")
```

## argparse

```python
import argparse

def get_args():
    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks',
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('-e', '--epochs', metavar='E', type=int, default=500,
                        help='Number of epochs', dest='epochs')
    parser.add_argument('-b', '--batch-size', metavar='B', type=int, nargs='?', default=1,
                        help='Batch size', dest='batchsize')
    parser.add_argument('-l', '--learning-rate', metavar='LR', type=float, nargs='?', default=0.0001,
                        help='Learning rate', dest='lr')
    parser.add_argument('-f', '--load', dest='load', type=str, default=False,
                        help='Load model from a .pth file')
    parser.add_argument('-s', '--scale', dest='scale', type=float, default=0.5,
                        help='Downscaling factor of the images')
    parser.add_argument('-v', '--validation', dest='val', type=float, default=10.0,
                        help='Percent of the data that is used as validation (0-100)')
    return parser.parse_args()
```

# 代码编写层面

## OpenCV预处理图像

## tensorboard可视化

只用了一个简单的，其他的看官方文档~

```python
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter()
writer.add_scalar("val avg miou", miou, epoch)
writer.add_scalar("valavg loss", loss, epoch)
```

**源码注释**

```python
def add_scalar(self, tag, scalar_value, global_step=None, walltime=None):
"""
Add scalar data to summary.

Args:
    tag (string): Data identifier
    scalar_value (float or string/blobname): Value to save
    global_step (int): Global step value to record
    walltime (float): Optional override default walltime (time.time())
"""
```



# 训练层面

## set的划分

训练的时候要划分好train set和validation set。一般是 `8：2`或 `9：1`

用validation set做测试，查看训练的效果。

模型的保存上，我即保存了train set上的最优参数，也保存了validation set上的最优参数。

```python
from torch.utils.data import DataLoader, random_split

dataset = BasicDataset(BASE_DIR.IMAGE_DIR, BASE_DIR.MASK_DIR, img_scale)
n_val = int(len(dataset) * val_percent)
n_train = len(dataset) - n_val
# 把dataset随机划分
train, val = random_split(dataset, [n_train, n_val])
train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)
```

