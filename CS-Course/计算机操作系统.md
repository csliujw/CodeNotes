# 计算机操作系统

## 目录

- [概述](#概述)
- [进程管理](进程管理.md)
- [内存管理](md)
- [设备管理](md)
- [链接](md)
- [文件管理]()
- [IO管理]()

## 参考资料

- 汤子瀛, 哲凤屏, 汤小丹. 计算机操作系统
- [慕课网课程大学计算机必修课新讲--编译原理+操作系统+图形学_课程 (imooc.com)](https://coding.imooc.com/learn/list/432.html)
- 深入理解计算机系统

# 概述

* 基本概念
* 基本特征
  * 并发
  * 共享
  * 虚拟
  * 异步
* 基本分类（了解）
* 基本功能
  * 进程管理
  * 内存管理
  * 文件管理
  * 设备管理
* 系统调用
* 大内核和微内核
  * 大内核
  * 微内核
* 中断分类
  * 外中断
  * 异常
  * 陷入

## 基本概念

### 操作系统基本概念

* 控制和管理整个计算机系统的硬件和软件资源
* 并合理地组织调度计算机地工作和资源地分配，
* 以提供给用户和其他软件方便的接口和环境，
* 是计算机系统中最基本的系统软件

### 功能和目标

- 管理系统资源：硬件资源+软件资源

```mermaid
graph
提供的功能-->处理机管理
提供的功能-->存储器管理
提供的功能-->文件管理
提供的功能-->设备管理
目标-->安全目标
目标-->高效
```

- 作为用户和计算机硬件之间的接口

```mermaid
graph
接口-->命令接口
接口-->程序接口
接口-->GUI
命令接口-->允许用户直接使用
命令接口-->分类-->联机命令接口\脱机命令接口
程序接口-->由一组系统调用组成,允许用户通过程序间接使用
GUI-->现代操作系统中最流行的图形用户接口
```

* 作为最接近硬件的层次
* 对硬件机器的扩展
* 方便用户使用

## 基本特征

### 并发

并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。

并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

操作系统通过引入进程和线程，使得程序能够并发运行。

<b>并发与并行的区分</b>

* 并发是一个时间段内交替执行
* 并行是一个时间点内同时执行

### 共享

共享是指系统中的资源可以被多个并发进程共同使用。

有两种共享方式：互斥共享和同时共享。互斥共享的资源称为临界资源，

* 互斥共享方式：
  * 一段时间只允许一个进程访问，该进程访问完后才允许下一个访问。
  * 例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。
* 同时共享方式：
  * 宏观上同时，微观上交替执行

<b>并发和共享的关系</b>

* 没有程序的并发执行，一次只能执行一个程序，也就没有必要共享资源了。反正一次就一个程序，可以随意独占资源
* 没有资源的共享，程序的并发也很难进行。不能共享 CPU，程序无法执行，不能共享需要的必要资源，程序无法正常运行。
* 没有离开共享的并发，也没有无并发的共享。

### 虚拟

虚拟技术把一个物理实体转换为多个逻辑实体。`物理-->逻辑`

主要有两种虚拟技术：

- 时（时间）分复用技术
  - 利用某设备为一用户服务的空闲时间，转去为其他用户服务；尽量不让设备空闲。
- 空（空间）分复用技术
  - 利用存储器的空闲空间分区域存放和运行其他多道程序，以此提高内存的利用率；尽量不让空间空闲。

<span style="color:orange">多个进程能在同一个处理器上并发执行使用了时分复用技术</span>，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

<span style="color:orange">虚拟内存中内存的换入换出使用了空分复用技术。</span>它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

### 异步

异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。（不知道何时完成）

### 总结

- 并发和共享是最基本的特征
- 理解并发和并行的区别
- 并发和共享互为存在条件
- 没有并发和共享，就谈不上虚拟和异步，因此并发和共享是 OS 的两个最基本的特征

## 基本分类（了解）

### 手工阶段

没有操作系统阶段，所有工作要人干预，用户独占全机。人机矛盾（处理程序的速度和资源利用率之间的矛盾）越来越大

### 批处理阶段

为解决人机矛盾及 CPU 和 IO 设备之间的速度不匹配问题出现了批处理操作系统。

* 单道批处理：
  * 目的：缓解人机矛盾
  * 优点：缓解了一定程度的人机速度矛盾，资源利用率有所提升
  * 缺点：内存中仅能有一道程序运行，只有该程序运行结束之后才能调入下一道程序。CPU 有大量的时间是在空闲等待 IO 完成，资源利用率依然很低
* 多道批处理：
  * 目的：为进一步提高资源的利用率和系统吞吐量
  * 优点：
    * 多道程序并发执行，共享计算机资源。资源利用率大幅提升
    * CPU 和其他资源保持忙碌状态，系统吞吐量增大。
  * 缺点：用户响应时间过长，不提供人机交互能力
* 多道批处理需要解决的问题
  * 处理机争用问题
  * 内存分配和保护问题
  * IO 设备分配问题
  * 文件的组织和管理问题
  * 用户与系统接口问题

### 分时操作系统

* 目的：提供人机交互
* 技术：采用的分时技术：时间片
* 缺点：不能优先处理一些紧急任务。
* 特征：同时性，交互性，独立性，及时性

### 实时操作系统

* 目的：为了能在某个时间限制内完成某些紧急任务而不需要时间片排队（十分注重及时性）
* 可分为软硬两种
  * 软实时操作系统：允许偶尔错过任务截至时间
  * 硬实时操作系统：不允许错过任务截至时间
* 如：飞行自动控制系统；飞机订票系统；银行管理系统

### 网络操作系统

网络中各种资源共享，各台计算机之间的通信

### 分布式操作系统

分布式和并行，若干台计算机相互协同完成某一任务

### 个人计算机操作系统

* 单用户单任务操作系统
* 单用户多任务操作系统
  * 只允许一个用户上机，但允许用户把程序分为若干个任务并发执行
* 多用户多任务操作系统
  * 允许多个用户通过终端共享资源，每个用户程序又可进一步分为多个任务，增加系统吞吐量。

## 系统调用

系统调用是操作系统提供给应用程序使用的接口，可理解为一种可供应用程序调用的特殊函数，应用程序通过系统调用请求来获得操作系统的服务。

如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。

<div align="center"><img src="os/system_call.png"></div>

<b>系统调用按功能分类可分为如下几类：</b>

* 设备管理：完成设备的请求、释放、启动等功能
* 文件管理：完成文件的读、写、创建、删除等功能
* 进程控制：完成进程的创建、撤销、阻塞、唤醒等功能
* 进程通信：完成进程之间的消息传递、信号传递等功能
* 内存管理：完成内存的分配、回收等功能

<b>Linux 的系统调用主要有以下这些：</b>

|   Task   | Commands                    |
| :------: | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
|   安全   | chmod(); umask(); chown();  |

<b>系统调用和库函数的区别</b>

* 系统调用是操作系统向上层提供的接口
* 有的库函数是对系统调用的进一步封装
* 当今编写的应用程序大多是通过高级语言提供的库函数间接地进行系统调用

<b>系统调用的具体过程</b>

系统调用发生在用户态。是用户向系统请求调用，所以是发生在用户态。对系统调用的处理发生在核心态。是 OS 对调用进行处理，分配资源等。执行陷入指令会产生内中断，使处理器从用户态进入核心态。

* 传递系统调用参数
* 执行陷入指令
* 执行系统调用相应服务程序
* 返回用户程序

## 大内核和微内核

### 大内核

大内核是将操作系统功能作为一个紧密结合的整体放到内核。

由于各模块共享信息，因此有很高的性能。但是由于内核代码庞大，结构相对混乱，难以维护。

### 微内核

由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。

在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。

因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。但是内核功能少，结构清晰，方便维护。

<div align="center"><img src="os/microkernelArchitecture.jpg"></div>

## 中断分类

中断机制的诞生目的是为了实现多道程序并发执行。

当中断发生时，CPU 立即进入核心态；当中断发生后，当前运行的进程暂停运行，并由 OS 内核对中断进行处理；对于不同的中断信号，会进行不同的处理。

### 外中断

由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

<b>外中断的处理过程如下</b>

* 每条指令执行结束后，CPU 检查是否有外部中断信号
* 若有外部中断信号，则需要保护被中断进程的 CPU 环境
* 根据中断信号类型转入相应的中断处理程序
* 恢复原进程的 CPU 环境并退出中断，返回原进程继续往下执行

### 异常

由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

### 陷入

在用户程序中使用系统调用。

# 进程管理

- 进程的引入
- 进程与线程
- 进程状态的切换
- 进程调度算法
- 进程同步
- 经典同步问题
- 进程通信

## 进程的引入

为什么要引入进程？引入进程是为了更好地描述控制程序的并发执行，实现操作系统的并发性和共享性。

## 进程与线程

### 进程

* ①进程是程序的一次执行过程，是资源分配的基本单位。
* ②进程是一个程序及其数据在处理机上顺序执行时所发生的活动。
* ③进程是具有独立功能的程序在一个数据集合上运行的过程，是系统进行资源分配和调度的一个基本单位。这里的系统资源是指处理机、存储器、和其他设备服务于某进程的“时间”。

进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，进而控制和管理进程。所谓的创建进程和撤销进程，都是指对 PCB 的操作。

下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。

<div align="center"><img src="os/create_thread.png"></div>

> 扩展内容

PCB，常驻内存，是进程实体的一部分，进程存在的唯一标志。创建进程实际上就是创建 PCB

PCB 的组成

* 进程描述信息：进程标识符 PID、用户标识符 UID
* 进程控制和管理信息：进程当前在状态、进程优先级
* 资源分配清单：程序段指针、数阶段指针、键盘、鼠标
* 处理机相关信息：各种寄存器

程序段是指能被进程调度程序调度到 CPU 执行的程序代码，它可被多个进程共享，即多个进程可运行同一个程序。

数据段是指进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间结果或最终结果。

进程的特征：

- 动态性：进程是程序的一次执行过程，是动态地产生、变化和消亡地

- 并发性：内存中有多个进程实体，各进程可并发执行

- 独立性：进程是能独立运行、独立获得资源、独立接受调度的基本单位

- 异步性：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供进程同步机制来解决异步问题

- 结构性：每个进程都会配置一个 PCB。结构上看，进程由程序段、数据段、PCB 组成

### 线程

线程是独立调度的基本单位。

一个进程中可以有多个线程，它们共享进程资源。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

<div align="center"><img src="os/thread.png"></div>

### 区别

Ⅰ 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

Ⅱ 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

Ⅲ 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

Ⅳ 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

### 实现方式

<b>用户级线程</b>：所有工作都由应用程序完成，内核意识不到线程的存在。

<b>内核级线程</b>：所有工作由内核完成，应用程序没有进行线程管理的代码。

多线程模型

* 多对一模型：
  * 特点：多个用户级线程映射到一个内核级线程
  * 优点：线程管理在用户空间进行，不需要切换到核心态，线程管理的系统开销小，效率高。
  * 缺点：当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高。多个线程不可在多核处理机上并发运行【一个线程被阻塞，其余的也被阻塞了】
* 一对一模型：
  * 特点：每个用户级线程映射到一个内核级线程
  * 优点：并发能力强
  * 缺点：创建线程开销大，影响性能
* 多对多模型：
  * 特点：集二者之长，n 个用户级映射到 m 个内核级（n>m）
  * 优点：克服了多对一模型并发度不高的缺点；克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。

## 进程状态的切换

<div align="center"><img src="os/ProcessState.png"></div>

- 就绪状态（ready）：已经具备运行条件，但是缺少 CPU 资源
- 运行状态（running）：占有 CPU，并在 CPU 上运行
- 阻塞状态（waiting）：因等待某一事件而暂停不能运行，如等待 IO

应该注意以下内容：

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

## 进程调度算法

调度是为了合理处理计算机软硬件资源。

### 调度概念

对处理机进行分配，从就绪队列中，按一定的算法（公平，高效）选择一个进程将处理机分配给它，实现进程并发执行。

操作系统的调度分为如下三大类：

* 作业（高级）调度：内存与辅存之间的调度，面向作业的，发生频率低。
* 中级（内存）调度：为了提高内存利用率，将暂时不用运行的进程从内存中调出，将需要运行调入内存。面向进程的，发生频率中等。
* 进程（低级）调度：操作系统中最基本的调度，调度频率很高。

作业调度是为进程活动做准备，进程调度使进程正常活动起来，中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间。

* 为减轻系统负载，提高资源利用率，暂时不执行的进程会被调到外存从而变成“挂起态”
* 七状态模型：在五状态模型的基础上加入了<b>“就绪挂起”</b>和“<b>阻塞挂起”</b>两种状态

抢占式调度和非抢制式调度

* 剥夺调度方式（抢占式），如果有更重要或更紧迫的进程需要使用处理机时，则立即停止当前执行的进程
* 非剥夺调度方式（非抢制式）
  * 只允许进程主动放弃处理机
  * 优先权、短进程优先、时间片原则
  * 对提高系统吞吐率和响应效率都有明显的好处

不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

### 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

<b>先来先服务 first-come first-serverd（FCFS）</b> 

非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

<b>短作业优先 shortest job first（SJF）</b>  

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。另外作业/进程的运行时间由用户提供的，并不一定真实，不一定能做到真正的短作业优先。

<b>最短剩余时间优先 shortest remaining time next（SRTN）</b>

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

SJF 和 SRTN 都会导致饥饿，如果有源源不断地短作业/进程来到，可能使长作业/进程长时间得不到服务，导致饥饿。

### 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

<b>时间片轮转</b>  

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法是一个抢占式的，由时钟装置发出时钟中断来通知 CPU 时间片已到。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

<div align="center"> <img src="os/time_slice.png"/> </div>

<b>优先级调度</b>  

为每个进程分配一个优先级，根据任务的紧急程度来决定处理顺序。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。一般情况下，系统进程优先级高于用户进程；前台进程优先级高于后台进程；OS 更偏好 IO 型进程

<b>多级反馈队列</b>  

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。而多级反馈队列是时间片轮转和优先级调度的综合。

算法思想：

* 设置多个就绪队列，不同优先级，第一级优先级最高。每次进程执行完后就挂到下一级的队尾。
* 各个队列的时间片也不同。如第一级最短，第二级是第一级的 2 倍，依此类推。

<div align="center"> <img src="os/multilevel_feedback_queue.png"/> </div>

多级反馈队列对各类型进程相对公平，每个新到达的进程都可以很快就得到响应，短进程只用较少的时间就可以完成。并且不必事先估计进程的运行时间可以防止用户作假，可灵活地调整对各类进程地偏好程度。

如同时处理 CPU 密集型进程和 IO 密集型进程时，可以将因 IO 而阻塞地进程重新放回原队列，这样 IO 型进程就可以保持较高优先级。

### 实时系统

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

## 进程同步

为协调进程之间的相互制约关系，引入进程同步的概念

### 临界区

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```c
do{
	entry section 			//进入区
	critical section		//临界区
	exit section			//退出区
	remainder section	//剩余区
}while(true)	
```

* 把一次仅允许一个进程使用的资源称为临界资源
* 许多物理设备都属于临界资源
* 对临界资源都必须互斥进行，访问临界资源的那段代码叫临界区

### 同步与互斥

- 同步：描述进程间的关系，也叫直接制约关系，源于进程间的相互合作，同步会使进程有一定的先后执行关系。
- 互斥：描述资源的使用，也叫间接制约关系。多个进程在同一时刻只有一个进程能进入临界区。

### 信号量机制

信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

-   <b>down</b>：如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
-   <b>up</b>：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了<b>互斥量（Mutex）</b>，0 表示临界区已经加锁，1 表示临界区解锁。

生产者消费者系列的问题在实际开发中推荐使用同步阻塞队列完成。

### 管程

使用信号量机制实现的生产者消费者问题编程很麻烦且容易出错，因此引入管程来简化代码的编写。

> 管程的组成

* 共享数据结构
* 对数据结构初始化的语句
* 一组可以用来访问数据结果的过程(函数)

> 基本特征

* 各外部进程\线程只能通过管程提供的特点入口才能访问共享数据
* 每次仅允许一个进程在管程内执行某个内部过程

> 补充

* 管程必须互斥访问管程的特性是由编译器实现的
* 可在管程中设置条件变量及等待、唤醒操作以解决同步问题

## 进程通信

进程通信即进程之间的信息交互。进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

> 问题：为什么会有进程通信，不能直接访问吗？

* 不能，进程是分配系统资源的单位（包括内存地址空间）因此各进程拥有内存地址空间相互独立。
* 为保证安全，一个进程不能直接访问另一个进程的地址空间
* 但是为了让他们可以安全通信，OS 提供了一些方法

### 管道

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

```c
#include <unistd.h>
int pipe(int fd[2]);
```

具体做法

* 设置一个特殊的共享文件（管道），其实就是一个缓冲区。
* 一个管道只能实现半双共通信。
* 实现双向同时通信要建立两个管道。
* 各进程要互斥访问管道。
* 写满时，不能再写，读空时，不能再读。
* 没写满，不能读，没读空，不能写。
* 必须提供的协调能力：互斥，同步和确定对方存在。

管道通信的限制：

- 只支持半双工通信（单向交替传输）；
- 只能在父子进程或者兄弟进程中使用。

<div align="center"><img src="os/pipeline.png"></div>

### FIFO

也称为命名管道，去除了管道只能在父子进程中使用的限制。

```c
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

<div align="center"><img src="os/FIFO.png"></div>

### 消息队列

相比于 FIFO，消息队列具有以下优点：

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

### 信号量

它是一个计数器，用于为多个进程提供对共享数据对象的访问。

### 共享存储

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

### 套接字

可用于不同机器间的进程通信。

# 死锁

死锁是在并发环境下，各进程因竞争资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。

## 必要条件

死锁的产生需要满足以下四个必要条件，缺一不可。

* <b>互斥条件</b>：资源需要互斥使用
* <b>不剥夺条件</b>：进程所获得的资源在未使用完之前不能由其他进程强行夺走，只能主动释放
* <b>请求和保持条件</b>：进程已经保持了至少一个资源，但又提出了新的资源请求，对自己的资源又不释放。
* <b>循环等待条件</b>：注意！发生死锁时一定有循环等待，但是发生循环等待时未必有死锁

发生死锁的情况

* 对系统资源的进程
* 进程推进顺序非法
* 信号量的使用不当
* 总结：对不可剥夺资源的不合理分配可能导致死锁

## 处理策略

* 鸵鸟策略：不处理死锁。
* 死锁预防：破坏死锁产生的四个必要条件。
* 死锁避免：避免系统进入不安全状态【银行家算法】。
* 死锁的检测和恢复：允许死锁发生，系统负责检测出死锁并解除。

### 鸵鸟策略

把头埋在沙子里，假装根本没发生问题。

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

### 死锁预防

在程序运行之前预防发生死锁。

<b>破坏互斥条件</b>：允许互斥资源可以共享，如共享打印机。但是不是所有的资源都可以改造成共享的，有些资源必须保护这种互斥性。

<b>破坏不可剥夺条件</b>：进程的资源可被剥夺

- 方案一：进程申请新的资源得不到满足，则释放保持的所有资源
- 方案二：某个进程需要的资源被其他进程占有时，操作系统选择好进程进行资源剥夺。
- 缺点：实现起来比较复杂；释放资源会导致进程前面的工作无效；反复申请和释放资源会增加系统开销，降低系统吞吐量；采用方案一可能导致进程饥饿，一直被剥夺资源，得不到执行。

<b>破坏请求和保持条件</b>：采用静态分配方法，进程在运行前一次申请完他所需要的全部资源，资源未得到满足时不让它投入运行。缺点是，可能会导致某些进程饥饿，某些资源进程只需要使用很少的时间，整个运行期间却一直保持，资源利用率极低。

<b>破坏循环等待条件</b>：给资源编号，必须按编号从小到大的顺序申请资源。缺点是不方便增加新设备；会导致资源浪费；用户编程麻烦。

### 死锁避免

在程序运行时避免发生死锁。

* 安全序列：系统按照这种序列分配资源，则每个进程都能顺利完成。
* 银行家算法：将资源分配给你后不会产生死锁，则分配资源给你，否则不分配。

#### 安全状态

<div align="center"> <img src="os/fig-6-9.png"/> </div>

图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。

定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。

#### 单个资源的银行家算法

一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

<div align="center"> <img src="os/fig-6-11.png"/> </div>

上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。

#### 多个资源的银行家算法

<div align="center"> <img src="os/fig-6-12.png"/> </div>

上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。

检查一个状态是否安全的算法如下：

- 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
- 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
- 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

如果一个状态不是安全的，需要拒绝进入这个状态。

### 死锁的检测和恢复

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

#### 每种类型一个资源的死锁检测

<div align="center"> <img src="os/fig-6-5.png"/> </div>

上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。

每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

#### 每种类型多个资源的死锁检测

<div align="center"> <img src="os/e1eda3d5-5ec8-4708-8e25-1a04c5e11f48.png"/> </div>

上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P<sub>1</sub> 和 P<sub>2</sub> 所请求的资源都得不到满足，只有进程 P<sub>3</sub> 可以，让 P<sub>3</sub> 执行，之后释放 P<sub>3</sub> 拥有的资源，此时 A = (2 2 2 0)。P<sub>2</sub> 可以执行，执行后释放 P<sub>2</sub> 拥有的资源，A = (4 2 2 1) 。P<sub>1</sub> 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

1. 寻找一个没有标记的进程 P<sub>i</sub>，它所请求的资源小于等于 A。
2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
3. 如果没有这样一个进程，算法终止。

#### 死锁恢复

- 资源剥夺法
- 撤销进程法
- 进程回退法

# 内存管理

## 内存管理的必要性

多道程序的并发执行，进程之间还共享了主存储器。共享主存储器会带来一些挑战，不对内存进行管理，容易导致内存数据的混乱，所以为了更好的支持多道程序并发执行，必须进行内存管理。

## 内存的基础知识

进程运行的基本原理

程序的三种链接方式：

- 静态链接：
  - 在程序运行之前就将各个目标模块及它们所需的库函数连接成一个完整的可执行文件，之后不再拆开
- 装入时动态链接：
  - 将各目标模块装入内存时，边装入边链接的链接方式
- 运行时动态链接：
  - 在程序执行中需要该目标模块时，才对它进行链接。
  - 优点是便于修改和更新，便于实现对目标模块的共享
  - 用不到的模块不需要装入内存

三种装入方式：

- 绝对装入：
  - 按照装入模块中的地址将程序和数据装入内存
  - 程序中的逻辑地址和实际内存地址完全相同
  - 只适用于单道程序
- 静态重定位【可重定位装入】：
  - 装入时对地址进行重定位，将逻辑地址变为物理地址【地址变换是在装入时一次完成的】
  - 特点：
    - 在一个作业装入内存时，必须分配其要求的全部内存空间
    - 若没有足够的内存则不能装入该作业。
    - 作业一旦进入内存后，在运行期间就不能再移动，也不能再申请内存空间
- 动态重定位：
  - 装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把地址转换推迟到程序真正要执行时才进行
  - 需要重定位寄存器的支持
  - 采用动态重定位时允许程序在内存中发生移动：
    - 程序的内容整体平移
    - 重定位寄存器的值也设置好具体的偏移量即可

## 虚拟内存管理

<b>思考</b>

- 为什么要引入虚拟内存？因为内存不够用。
- 虚拟内存空间的大小由什么决定？
  - 虚存的大小 ≤ 内存容量和外存容量之和。
  - 虚存的大小 ≤ 计算机地址位数能容纳的最大容量（若 32 位地址，一地址代表 1B 则虚存大小 ≤ 4GB）。
- 虚拟内存怎么解决问题的？会带来什么问题？
  - 使用外存扩充了内存。
  - 调换页面需要访问外存，会导致平均访问内存时间下降。

<b>基本概念</b>

传统存储方式作业必须一次全部装入内存，才能运行。作业被装入内存后，就一直停留在内存中。然而运行中的进程会因 IO 阻塞等，长期处于等待状态，如果一直占着这部分内存空间的话，系统的内存将会被这个进程一直占据，知道进程执行完毕。

程序的运行有一个局部性原理：时间局部性和空间局部性。时间局部性是指，执行了某条指令，不久后该指令很可能再次执行。空间局部性是指一旦访问了某个存储单元，不久后其附近的存储单元也很有可能被访问。局部性原理的典型应用有 CPU 的 Cache 缓存和后面即将讨论的快表。

虚拟内存管理正是利用了程序的局部性原理，将程序的部分内容装入内存，其余留在外存，当访问的信息不存在时便从外存中调入。

虚拟存储器的大小是由计算机地址结构决定。虚拟内存的最大容量是由计算机的地址结构【CPU寻址范围】确定的。虚拟内存的实际容量 = min（内存和外存容量之和，CPU寻址范围）

例题：某计算机地址结构为 32 位，按字节编址。计算机的内存大小为 512MB，外存大小为 2G。

- $虚拟内存的最大容量为 2^{32}B = 4GB$
- $虚拟内存的实际容量 = min（2^{32}B,512MB+2GB）= 2GB + 512MB$

虚拟内存有三个主要特性：多次性，程序无需一次全部装入，可多次装入；对换性，无需作业运行时一直常驻内存，运行在运行时进行换进换出；虚拟性从逻辑上扩充内存，使用户看到的内存容量，远大于实际的容量。

<b>目的</b>

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0\~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

<div align="center"><img src="os/virtual_memory.png"></div>

比如，我们玩 GTA5，这个游戏有几十 G，如果没有虚拟内存，我们就无法启动这个游戏。

那么虚拟内存是如何映射到物理内存的呢？是通过内存管理单元（MMU）进行虚拟内存和物理内存映射的

```mermaid
graph LR
虚拟内存-->|MMU|物理内存
```

## 分页系统地址映射

内存管理单元（MMU，CPU 上的硬件）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

对一台内存为 256MB 的 32bit x86 主机，其虚拟地址空间范围是 `0~0xffff ffff (8GB)` 而物理地址空间范围是 `0~0x0fff ffff (256MB)`。在没有使用虚拟存储器的机器上，地址被直接送到内存中序上，使用具有童谣地址的物理存储器读写；使用了虚拟存储器的情况下，虚拟地址先被送到 MMU，然后进行内存映射。

CPU 是如何得到虚拟存储地址的呢？编译器将代码编译成机器码时，给变量的地址是家地址，CPU 所指向的指令里面包含的就是虚拟地址。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

<div align="center"> <img src="os/page_table.png"/> </div>

### 快表

程序的运行是具备局部性原理的。时间局部性：如果某个数据被访问过，不久之后该数据很可能再次被访问，因为程序中存在大量的循环；空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问，因为很多数据都在内存中是连续存放的。

页表的读取也符合程序的局部性原理，因此引入快表来加速页面的查找。快表是一种硬件，在具有快表的计算机中，查询页面是否存在是先查快表再查页（或同时查快表和页表）。

单级页表的问题：

- 问题 1：页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框。
- 问题 2：没有必要让整个页表常驻内存，因此进程在一段时间内可能只需要访问某几个特定的页面。

引入多级页表

## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

### 最佳页面置换算法

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

```html
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 最近最久未使用算法

> LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

```html
4，7，0，7，1，0，1，2，1，2，6
```

<div align="center"> <img src="os/os_lru.png"/> </div>

### 最近未使用算法

> NRU, Not Recently Usedv

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 先进先出算法

> FIFO, First In First Out

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面也被换出，从而使缺页率升高，违法程序的局部性原理。

### 第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

<div align="center"> <img src="os/fifo-2.png"/> </div>

### 时钟算法

> Clock

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

<div align="center"> <img src="os/clock.png"/> </div>

## 分段系统地址映射管理

分段是指将地址空间按照程序自身的逻辑关系划分为若干个段，每段从0开始编址，每个段在内存中占据连续空间，但各段之间可以不相邻，其逻辑地址结构为：（段号，段内地址）

段表记录逻辑段到实际存储地址的映射关系，每个段对应一个段表项。各段表项长度相同，由段号【隐含】、段长、基址组成

<b>分段 VS 分页</b>

- 分页对用户是不可见的，分段对用户可见
- 分页的地址空间是一维的，分段的地址空间是二维的。
- 分段更容易实现信息的共享和保护【纯代码/可重入代码可以共享】
- 分页【单级页表】、分段访问一个逻辑地址都需要两次访存。分段存储中也可以引入快表机构

## 段页式系统地址映射管理

分页管理内存利用率高，不会产生外部碎片，只会有少量的页内碎片但是不方便按照逻辑模块实现信息的共享和保护。

分段管理方便按照逻辑模块实现信息的共享和保护。但是，如果段长过大，为其分配很大的连续空间会很不方便。另外，段式管理会产生外部碎片，虽然分段管理中产生的外部碎片也可以采用紧凑来解决，但是要付出较大的时间代价

而段页式管理则是一种折中策略。程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

## 分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。

- 地址空间的维度：分页是一维地址空间，分段是二维的。

- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。

- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

# 设备管理

重点内容在磁盘调度算法

## 磁盘结构

- 盘面（Platter）：一个磁盘有多个盘面；
- 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；
- 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
- 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；
- 制动手臂（Actuator arm）：用于在磁道之间移动磁头；
- 主轴（Spindle）：使整个盘面转动。

<div align="center"> <img src="os/014fbc4d-d873-4a12-b160-867ddaed9807.jpg"/> </div><br>

## 磁盘读/写

$一次磁盘读/写操作所需要的时间=寻道时间+延迟时间+传输时间$

* 寻找时间（寻道时间）：启动磁头臂时间 + 移动磁头时间
  * 启动磁头臂--耗时 s
  * 移动磁头--跨越一条磁道耗时 m，共要跨 n 条
* 延迟时间：
  * 旋转磁盘，使磁头移动到指定扇区所需要的时间。--转速 r，平均所需的延迟时间 Tr = 1/2r。转半圈的时间。平摊分析。
* 传输时间：
  * 从磁盘读出或写入数据所需的时间
  * 假设磁盘转速为 r，此次读写字节数为 b，每个磁道上的字节数为 N
  * Tr = b/rN
    * b 个字节存储在 b/N 个磁道上
    * 每读写一个磁道所需的时间刚好是转一圈所需的时间 1/r

## 磁盘调度算法

常见的磁盘调度算法有这几种：先来先服务（FCFS）、最短寻找时间优先（SSTF）、扫描算法（SCAN）、循环扫描算法（C-SCAN）

而读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度算法的主要目标是使磁盘的平均寻道时间最短。

### 先来先服务

> FCFS, First Come First Served

按照磁盘请求的顺序进行调度。

优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，访问的磁道比较分散时，寻道时间长，性能差，平均寻道时间可能较长。

### 最短寻道时间优先

> SSTF, Shortest Seek Time First

优先处理离磁头最近的磁道，只选眼前最优。可能会产饥饿。

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

<div align="center"> <img src="os/SSTF.png"/> </div>

### 电梯算法

> SCAN

类似于电梯。只向一头移动，要移动到最外侧，即便是没有要处理的磁道请求，也要移动到最边上。考虑了移动方向，所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。

<div align="center"> <img src="os/scan.png"/> </div>

SCAN 有几个改进版本

> LOOK 调度算法（SCAN 的改进）

没有请求了，就直接掉头

> 循环扫描算法 C-SCAN：

SCAN 算法的改进，掉头过程中不进行磁道处理（也是没有请求了直接掉头）

> C-LOOK 算法（循环 C-SCAN 的改进）

循环 C-SCAN 的改进，掉头时不必到另一侧的最边上，到最边上的第一个需要处理的磁道即可。

## 减少延迟时间的方法

* 如果磁盘连续编号。我们又要读取连续的磁盘的 2、3 号扇区
  * 磁盘需要一定的时间处理一块内容，不能连续不断的处理数据
  * 读完 2 号后，需要一定的时间处理数据，会错过读取 3 号扇区（磁头转过去了）
* 交替编号（逻辑相邻，物理不相邻）
  * 在物理上有一定的间隔，给予处理数据的时间
* 磁盘地址结构的设计
  * 思考？为什么磁盘的物理地址时（柱面号、盘面号、扇区号）而不是（盘面号、柱面号、扇区号）
  * 可以减少磁头移动，<b>不同盘面的同一扇区记录文件，找下一个扇区时就不用移动磁头臂了，只要激活对应的磁头即可。</b>
* 错位命名（减少延迟时间），就是给予充分的时间处理数据，不错过下一个扇区（即便是不同盘块也一样）

## 磁盘管理

* 磁盘初始化：
  * 低级格式化：将磁盘的磁道划分为扇区。采用特殊的数据结构，包括校验码
  * 磁盘分区：C、D、E 盘
  * 逻辑格式化：建立文件系统（建立根目录文件，建立用于存储空间管理的数据结构）
* 引导块：
  * 计算机启动时需要运行初始化程序（自举程序）来完成初始化
  * ROM 中存放很小的自举程序
  * 完整的自举程序放在初始块（引导块）中
* 坏块：
  * 简单的磁盘：逻辑格式化时将坏块标记出来
  * 复杂的磁盘：磁盘控制器维护一个坏块链，并管理备用扇区
  * <b>对坏块处理的实质是使系统不去使用坏块</b>

# 链接

## 编译系统


以下是一个 hello.c 程序：

```c
#include <stdio.h>

int main()
{
    printf("hello, world\n");
    return 0;
}
```

在 Unix 系统上，由编译器把源文件转换为目标文件。

```bash
gcc -o hello hello.c
```

这个过程大致如下：

<div align="center"> <img src="os/link.jpg" /> </div>

- 预处理阶段：处理以 # 开头的预处理命令；
- 编译阶段：翻译成汇编文件；
- 汇编阶段：将汇编文件翻译成可重定位目标文件；
- 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。

## 静态链接

静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：

- 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
- 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。

<div align="center"> <img src="os/static_link.jpg"/> </div>

## 目标文件

- 可执行目标文件：可以直接在内存中执行；
- 可重定位目标文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件；
- 共享目标文件：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接；

## 动态链接

静态库有以下两个问题：

- 当静态库更新时那么整个程序都要重新进行链接；
- 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。

共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点：

- 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中；
- 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。

<div align="center"> <img src="os/dummy_link.jpg"/> </div>

# 文件管理

## 索引文件

* 索引表中包含索引号，记录长度，记录所在磁盘的首地址
* 可直接通过指针找到对应的数据，通过长度，找到结束位置。
* 文件中的记录可以是离散存储的，因为我指针可以直接指向他们。每个记录抱持连续即可。
* 若索引表按关键字排序，则可支持快速检索（二分查找）
* 解决了顺序文件不方便增删记录的问题，同时让不定长记录的文件实现了随机存储，但是索引表可能占用很多空间

## 索引顺序文件

* 为文件建立索引表，但是是一组记录对应一个索引表项
  * 真题中设计逻辑结构、物理结构。逻辑结构上，按姓名建立索引顺序文件
  * 索引表中顺序查找，逻辑文件中顺序查找。10000 的分成两个 100 的
  * 查找从 $(1+10000)/2$ 变到了 $(1+100)/2 * 2$
* 如果文件数目过大，可以采用多级索引顺序文件，减少查找次数
* 检索记录时先顺序查找索引表、找到分组、再顺序查找分组。

## 目录结构

文件控制块【实现文件目录的关键数据结构】，实现按名存取

目录结构可分为单级目录、两级目录、多级目录和无环图这四种。

* 单级目录：整个系统中只建立一张目录表，每个文件占一个目录项，实现了按名存取，但是不允许重命名。
* 两级目录：分为主目录和用户目录，允许不同用户目录重命名。
* 多级（树形目录结构）：每次从根目录开始查找效率很低，可以设置当前目录，想要访问文件时从当前目录出发。多级目录方便分类，层次清晰，能有效地进行文件管理和保护，但是不便于实现文件共享。
* 无环图：用不同地文件名指向同一个文件【甚至是目录，共享同一目录下的所有内容】，为每个共享结点设置一个共享计数器，计数器减为 0 时才删除结点。

## 文件共享

文件的共享方式有两种，一种是基于索引结点（硬链接）的共享，另一种是利用符号链（软链接）来实现的共享

### 基于索引结点（硬链接）

* 各用户目录项指向同一个索引结点
* 索引结点中需要有链接计数 count
* 某用户想删除文件时，只是删除该用户的目录项，且 count--
* 只有 count==0 时才能真正删除文件数据和索引结点，否则会导致指针悬空

### 利用符号链实现（软链接）

* 在一个Link型的文件记录中共享文件的存放路径
* 操作系统根据路径一层一层查找目录，最终找到共享文件
* 即使软链接指向的共享文件被删除，Link 文件依然在，通过 Link 中的路径去查找共享文件会失败
* 访问共享文件时需要查询多级目录，会有多次磁盘 IO，速度比硬链接慢。【硬链接直接找到对应物理块？】

## 文件保护

文件保护的方式有三种：口令保护、加密保护、访问控制保护。

> 口令保护

* 为文件设置一个口令，用户想要访问文件时需要提供口令，由系统验证口令是否正确
* 实现开销小，但口令一般存放在 FCB 或索引结点中（也就是存放在系统中）不太安全

> 加密保护

* 用一个密码对文件加密，访问时需要解密
* 安全性高，但加密解密需要耗费时间【异或加密】

> 访问控制

* 用一个访问控制表（ACL）记录用户对文件的访问权
* 对文件的访问类型可分为：读、写、执行、删除等
* 实现灵活，可实现复杂的文件保护功能
* 即便 ACL 太大也可以进行缩减

