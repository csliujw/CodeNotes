# SegNet

## 博客&论文泛读

SegNet网络和FCN网络的结构比较像，都是基于分类网络的一部分作为编码器，去掉其全连接层，然后在后面增加解码器。区别是SegNet是把Softmax分类放在了最后，对每个像素输出一个类别的概率，而且在池化时候记录了最大池化的结果来自于池化块中的哪个元素，在解码器上采样的时候，按照之前记录的像素索引值去恢复，这样理论上可以取得更精确的结果。

### 网络结构

<img src="../../pics/CV/SegNet/SegNet_structure.jpg" style="float:left">

编码器部分采用的是VGG网络的前13层，每层包含卷积 + BN(批量规范化) + ReLU，解码器和编码器的每层一一对应，用来上采样恢复像素，最后跟一个softmax，输出每个像素的分类概率。

### 改进措施

<img src="../../pics/CV/SegNet/SegNet_max_pooling_Indices.jpg" style="float:left">

为了让分类结果更精细，作者提出了池化索引功能（pooling index），这也是本文的亮点。这一功能的工作过程可以结合下图说明。例如池化是`2x2`的大小，使用最大池化，即从4个数中选出一个最大值作为输出，如果不记录该最大值来自于那个元素，在解码阶段进行上采样恢复的时候，并不清楚需要往哪恢复，就丢失了信息。相反，如果记录了对应的索引值，那么就可以定向恢复相应的值，从而达到更好更精细的效果。

<img src="../../pics/CV/SegNet/SegNet_max_pooling_Indices_detail.jpg" style="float:left">

对比FCN可以发现SegNet在Unpooling时用index信息，直接将数据放回对应位置，后面再接Conv训练学习。这个上采样不需要训练学习(只是占用了一些存储空间)。反观FCN则是用transposed convolution策略，即将feature 反卷积后得到upsampling，这一过程需要学习，同时将encoder阶段对应的feature做通道降维，使得通道维度和upsampling相同，这样就能做像素相加得到最终的decoder输出。

## 博客论文笔记

<a href="https://zhuanlan.zhihu.com/p/36525939">笔记来源</a>

### Introduction

**网络结构**

- 编码网络和`VGG-16`的卷积层相同
- 移除了全连接层
- 解码器使用从相应的编码器接受的`max-pooling indices`来进行输入特征图的非线性`upsampling`

**解码网络中复用max-pooling indics的好处：**

- 改善了边界划分，【可精确还原特征】
- 减少了端到端训练的参数量
- 仅需要少量的修改而可合并到任何编码－解码形式的架构

本文分析了FCN、DeconvNet中的解码过程，并揭示了他们的优点和缺陷。

<img src="../../pics/CV/SegNet/SegNet_max_pooling_Indices_detail.jpg" style="float:left">

**Pascal VOC 12的偏向性**

- 数据集中大部分图都有一两个由高度多样的背景包围的前景。
- 隐含地导致其**偏向于**含有检测技术的算法

**不同分割论文解码方法总结**

- Decoupled，用大量弱标签数据进行分类网络的训练，使得分割网络性能得到改善。
- DeepLab，使用分类网络的特征图和独立的CRF后处理技术来执行分割。
- DeconvNet、Edge Boxes，使用区域proposals，通过额外的推理辅助来增强分割网络的性能。

因此，上面这些算法，它们与场景理解的不同之处在于，他们的目的是利用对象的共同出现（ co-occurrences of objects—CRF）以及其他空间上下文（other spatial-context—proposal）来执行可靠的分割。

### LITERATURE REVIEW

**前FCN时代的深度学习分割方法**

- 传统方法，手工设计特征
- 人们尝试将用于对象分类的网络应用于分割，通过对图像块分类来实现全图的分割，然而这样的方式得到的分类是块状的。
- 另一种方法是使用循环神经网络（RNN）合并几个低分辨率的预测图，来实现输入图像分辨率的预测。
- 这些技术已经是手工设计特征的改进，但是它们划定边界的能力差。

----

**FCN：**

- FCN架构中的每个解码器都对其输入的特征图进行上采样，并将其与相应的编码器特征图组合，以产生下一个解码器的输入。
- FCN编码器网络中有大量参数（134M），但解码器网络非常的小（0.5M）。
- 该网络的整体大小使其难以在相关任务上端到端地进行训练（即原始的FCN32s效果很差）。因此，作者使用了阶段性的训练过程。解码器网络中的每个解码器逐步添加到预训练好的网络中。
- 网络生长直到没有进一步的性能提高，这种增长在三个解码器之后停止（FCN8s）。

**FCN弊端：**

- 但是**忽略高分辨率的特征图肯定会导致边缘信息的丢失**。
- 除了训练的相关问题之外，**解码器中复用编码器特征图的方式使其在测试时显存消耗也很大**。

-----

通过**将循环神经网络（RNN）附加到FCN（CRF as RNN）**，并对其在大的数据集上（VOC、COCO）进行微调，FCN的预测性能进一步得到改善。在使用FCN的特征表征能力的同时，RNN层模仿了类似CRF的尖锐边界划分能力。比FCN8s显示出显着的改进，但也表明当使用更多训练数据训练FCN8s时，这种差异减小。值得注意的是，反卷积网络（DeconvNet）的性能明显优于FCN，但是以更复杂的训练和推理为代价。这提出了一个问题，即**随着核心的前馈分割引擎的改进，CRF-RNN的感知优势是否会减少**（DeepLab v3已经去掉了CRF，他们应该是问对了）。无论如何，CRF-RNN网络可以附加到任何深度分段架构，包括SegNet。

多尺度的深层架构也被广泛采用。它们有两种风格，(1)使用几个尺度的输入图像和相应的深度特征提取网络(2)组合来自单个深层结构的不同层的特征图（ParseNet）。

通常的想法是**提取多尺度特征来提供局部和全局的空间信息（zoom-out），再利用浅层编码层的特征图以保留更高频率的细节**，从而获得更细致的类别边界。其中一些架构由于参数太多而难以训练。因此，多阶段训练往往也需要数据增强。由于特征是从多个卷积路径提取的，导致推理过程也是复杂度比较高的。还有的团队在多尺度网络后附加CRF，并共同训练。然而，这个步骤在测试时不是前馈的，需要优化才能确定MAP标签。

最近提出的几种最新的分割结构（DeconvNet、deeplab、Decoupled）在推理时不是前馈的***（推理单独进行，与网络训练是分开的两个步骤）***。它们需要CRF的MAP推理或区域proposals等辅助工具。我们认为**使用CRF可以获得性能提升主要是由于这些网络在其核心的前馈分割引擎中缺乏良好的解码技术**。

DeconvNet及其半监督变体Decoupled利用编码器特征图的最大位置（pooling index），在解码器网络中执行非线性上采样。这些架构的作者独立于SegNet，提出了解码网络中的解码思想。然而，它们编码器网络中包括了占据整个VGG-16网络约90％参数的全连接层。这使得他们的网络训练起来非常困难，因此需要更多的辅助工具，例如使用区域proposals。此外，这也显著增加了推理时间。从benchmark的角度来看，由于使用了其他的辅助推理方式，我们也难以评估其架构中编码器-解码器网络的性能。DeepLab在不牺牲性能的情况下，在参数数量、内存消耗、推理时间之间取得了一个较好的平衡。

### ARCHITECTURE

<img src="../../pics/CV/SegNet/SegNet_structure.jpg" style="float:left">

上图为SegNet的网络结构图，Encoder交替采用conv+pooling，Decoder交替采用deconv+upsampling，用Softmax做像素分类。在Encoder-Decoder过程中，采用Pooling Indices（pooling时的位置信息）转移Decoder，改善了图像分割率（参考DeconvNet）<span style="color:green">**[去看下DeconvNet]**</span>

最大池化可以实现在输入图像上进行小的空间位移时保持平移不变性。**连续的下采样导致了在输出的特征图上，每一个像素都重叠着着大量的输入图像中的空间信息**。对于图像分类任务，多层最大池化和下采样由于平移不变性可以获得较好的鲁棒性，但导致了特征图大小和空间信息的损失。**图像分割任务中边界划分至关重要，而这么多有损边界细节的图像表示方法显然不利于分割**。因此，在进行下采样之前，**在编码器特征映射中获取和存储边界信息是十分重要的**。如果推理过程中的内存不受约束，则所有编码器特征映射(在下采样后)都可以存储。在实际应用中，情况通常不是这样，因此我们提出了一种更有效的方法来存储这些信息。它只存储最大池化索引，即存储每个池化窗口中最大特征值的位置，用于每个编码器特征映射。

Deconvnet具有更多的参数，需要更多的计算资源，并且很难进行端到端训练，主要是因为使用了全连接层。

U-Net没有利用池化位置索引信息，而是将编码阶段的整个特征图传输到相应的解码器（以牺牲更多内存为代价），并将其连接，再进行上采样（通过反卷积），从而得到解码器特征图。