# 汇报

## 第一步


- 介绍传统的两步走的目标检测方法，Mask R-CNN。 
    - 需要定义大量的proposals，anchors或window centers。
    - 这里的很多设计涉及到先验知识。（常识：举例 anchors大小的选择）
    - 这些proposals anchors可能会有很多重叠的部分。
- 对比介绍`DERT`网络，于Mask R-CNN相比，DERT的优势在哪里。
    - 结构更简单，没有proposals anchors 和 window centers等。直接预测需要检测的目标对象的集合。
    - DERT直接预测最终的目标集合，通过CNN+transformer结构。
    - 在训练期间，用二分图匹配算法对某个对象进行唯一的预测。每匹配到的则归类为空对象（背景）

## 第二步

- 将目标检测问题视为直接预测一个集合。集合中的值就是需要检测的那些对象。
- 采用流行的基于transformers encoder-decoder结构。
    - transformer的self-attention机制明确的对序列中元素之间的所有成对交互（pairwise interactions 成对关系）进行建模，使得这些架构特别适合有特定约束的集合预测（）。
- DERT一次预测所有物体，并且用一个集合损失函数进行端到端的训练，该函数在预测物体和ground truth之间进行二分匹配
- 简化了检测的过程，丢弃了spatial anchors or non-maximal suppression。
- 与先前的直接预测集合的工作相比，DETR的主要特点是 二分图匹配损失 和 并行的transformers解码。先前的工作主要是用RNNs进行autoregressive decoding。【我们的匹配损失函数唯一地将预测分配给一个地面真实对象，并且对于预测对象的排列是不变的，因此我们可以并行发射它们。】
- 用DETR做了一个全景分割的Demo。（大佬就是强）

## 第三步

- 我们的工作建立在先前的集合领域上：集合预测的二分匹配损失；encoder-decoder architectures based on the transformer；并行解码和对象检测方法
- 先前领域一：集合预测
    - 没有规范的深度学习模型可以直接预测集合。
    - 基本的集合预测任务是多标签分类，其基线方法“一对多”不适用于注入在元素之间存在底层结构检测等问题。这些任务的第一个困难是避免近似重复。大多数当前的检测器使用后处理，例如非最大抑制来解决这个问题，但是直接集预测不需要后处理。他们需要全局推理方案来模拟所有预测元素之间的相互作用，以避免冗余。对于恒定大小的集合预测，密集的全连通网络[9]是足够的，但代价很高。一般的方法是使用自回归序列模型，如递归神经网络（RNN，循环神经网络，无法并行？计算效率？）在所有情况下，损失函数应该通过预测的排列保持不变。通常的解决方案是基于匈牙利算法[20]设计一个损失，以找到基础事实和预测之间的二分匹配。这加强了排列不变性，并保证每个目标元素都有唯一的匹配。我们遵循双方匹配损失方法。然而，与大多数以前的工作相反，我们远离自回归模型（autoregressive model），使用具有并行解码的transformer，transformer将会在下面进行描述。
- 先前领域二：并行解码的transformers
    - 注意力机制是`从整个输入序列聚集信息`的神经网络。
    - transformers引入了self-attention层（类似于非局部神经网络，non-local神经网络，这个比较复杂，要去查一下）扫描序列的每个元素，并通过聚集整个序列的信息来更新它。
    - 基于注意力的模型，其主要又是之一是它们的`全局计算`和完美记忆，这使得它们比RNNs更适合长序列。
    - transformers逐渐被用于NLP和CV中。
    - `transformers使用历史`
        - 首先用于auto-regressive models，遵循早期的序列到序列的模型，一个接着一个的生成token。然而，令人望而却步的推理成本(`与输出长度成正比，且难以批量处理`)导致了在音频、机器翻译、单词表示学习以及最近的语音识别等领域中并行序列生成的发展【计算量和难以并行阻碍了它的发展】
    - 为了权衡计算成本和执行set prediction所需的全局计算成本，我们将transformers和并行解码器结合起来（并行可充分利用资源）
- 先前领域三：目标检测（很多其他方法都采用了较多的先验知识，如候选框，anchor）
    - 大多数现代的目标检测方法相对于一些最初的猜测做出预测。
    - two-stage检测方法的boxes预测涉及到候选框，single-stage的方法预测时涉及到anchors或者是可能的目标中心网格进行预测（a grid of possible object centers.）这些系统的最终性能，很大程度下取决于这些初始猜测的准确设置。
    - 在我们的模型中，我们可以去掉这个手工制作的过程，并通过与输入图像(而不是一个锚点)相关的绝对盒预测直接预测检测集合，从而简化检测过程。
    - `set-based loss：`几个目标检测器使用了二分匹配损失。然而，在这些早期的深度学习模型中，不同预测之间的关系仅用卷积或全连接层来建模，并且手工设计的`NMS`后处理可以提高它们的性能。最新的一些检测器使用非唯一的分配规则在ground truth和predictions之间使用了NMS。// 可学习的NMS方法和关系网络清晰地模拟了不同预测之间的关系。使用直接set loss，它们不需要任何后处理步骤。然而，这些方法使用额外的手工制作的上下文特征，如提议框坐标来有效地建模检测之间的关系，`同时我们寻找减少模型中编码的先验知识的解决方案。`
    - `Recurrent detectors：`最接近我们的方法是端到端集预测的对象检测和实例分割。与我们类似，他们使用基于CNN激活的编码器-解码器结构的两方匹配损失（bipartite-matching losses）来直接产生一组边界盒。然而，这些方法只是在小的数据集上进行评估，而不是根据现代基线。特别是，它们基于自回归模型(更精确的rnn)，因此它们没有利用最新的`并行解码的transformers`。

## 第四步 model

### 损失的计算

- **检测模型中有两个非常重要的因素**

（1）：集合损失预测，强制进行预测值和真实值之间的唯一匹配预测。

（2）：一个结构，什么结构？一次性预测一组对象并对它们的关系建模

- **DERT 目标检测集预测损失**
    - DETR通过解码器一次推断出一组固定大小的N个预测，N被设置为明显大于图像中需要检测对象的数量（`这对算力，显存来说是个挑战。可能部分图片只有10个对象需要检测，一些图片有100个对象需要检测，多数图片只有50个对象要进行检测。`）。训练的主要困难之一是对预测对象（类，位置，大小）和ground truth之间的评分（`评分到底怎么计算？？应该是想根据评分，大于xx分的归类于要检测的对象`）。我们的损失在预测对象和ground truth对象之间产生最佳的二分匹配（`二分匹配的计算方式`），然后优化特定对象(边界框)的损失（`损失的计算方式`）。

> 公式一：取最小值是参数对应的值。匈牙利算法求的是N-N配对的最小损耗。【通过该算法找优化方向，哪个gt由哪个slot负责】

![image-20210424104740817](..\..\pics\CV\ISG\Untitled\image-20210424104740817.png)

- 我们用y表示ground truth的对象集合。$\hat y=\{\hat y_i\}^N_{i=1}$是预测的结果，预测的对象有N个。N是远大于需要检测的对象数目的。ground truth集合y也是有N个元素的，为了确保y中的元素个数=N，需要一些空对象（背景）进行填充。

- 我们需要找到y与$\hat y$之间的最佳二分匹配。我们寻找具有最低成本的N个元素的排列。【`可是你总共都只才预测N个？搜索成本最小的，按成本从小到大取真实对象？那么预测图片的时候，取多少对象才合适？按score来嘛？`】

- $$
    L_{match}(y_i,\hat y_{\sigma}(i))
    $$

    是ground truth $y_i$和索引为$\sigma(i)$之间成对的匹配损失。这种最优分配是用匈牙利算法【有n个工作，需要指派给n个工人，每个工人完成每个工作的时间可能都不一样，给出一个算法，使得得到的指派结果总的时间最少】（https://zhuanlan.zhihu.com/p/89380238）计算出来的。

- 匹配成本考虑了类别预测以及预测的boxes与ground truth boxs之间的相似性（`这个相似性用什么度量的？`）

- ground truth中的每个元素可以被看作是$y_i = (c_i,b_i),c_i是类别标签，b_i是一个向量，定义了ground truth中心坐标和相对于图像大小的高度和宽度$

    $预测的索引为 \sigma(i)我们定义类别c_i为\hat p_{\sigma(i)}(c_i)，预测框定义为\hat b_{\sigma}(i)$

    因此我们把$L_{match}(y_i,\hat y_{\sigma(i)})$定义为
    $$
    -1_\{c_i \neq \varnothing  \} \hat p_{\sigma(i)}(c_{i}) + 1_\{c_i \neq \varnothing  \}L_{box}(b_i,\hat b_{\sigma(i)})
    $$
    [ 找到一对匹配来进行无重复的直接集合预测 ]

- 接下来就是计算损失了。就是上一步所有匹配对的匈牙利损失。我们对损失的定义类似于常规的目标检测那样：类别预测的负对数似然性和随后定义的box损失的线性组合:

    > 公式二

    $$
    L_{Hungarian(y,\hat y)} = \sum^{N}_{i=1}[ -log\hat p_{\hat \sigma(i)}(c_i)+1_{c_i \neq \varnothing}L_{box}(b_i,\hat b_{\hat \sigma}(i)) ]
    $$

    $\hat \sigma是先前计算的匹配最小的那一组集合$，当$c_i = \varnothing$时，我们对对数概率项的权重减低了10倍，一说明类别不平衡（`这块没理解！`）

    在匹配时用$\hat p_{\sigma(i)}(c_i)$替代对数概率。`匹配时这样做，那么在计算匈牙利匹配损失的时候，就可以与box损失同等度量（类别预测与box损失同一级别），且实验表明这样的效果更好？`

- Bounding box loss：

    - DERT的检测框直接预测，不做初始猜测。简化了检测的实现，但是带来了损耗的相对缩放问题（relative scaling of the loss）。

    - $l_1$损失对不同大小的boxes会有不同的刻度，即使它们的相对误差类似。因此最后box的损失采用的是$l_1$与 generalized IOU的线性组合。
        $$
        L_{box}(b_i,\hat b_{\sigma(i)})=\lambda _{iou}L_{iou}(b_i,\hat b_{\sigma}(i))+\lambda_{L_1}||b_i-\hat b_{\sigma(i)}||_1
        $$
        $\lambda_{iou}和\lambda_{L1}是超参数$

### `DETR`结构

> DETR的网络结构。代码输出下网络的具体结构。



## 第五步 实验结果

